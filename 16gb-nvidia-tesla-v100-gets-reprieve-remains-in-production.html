<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="VibeBlog"><meta property="og:type" content="article"><meta name=robots content="index,follow,noarchive"><meta property="og:image" content="//img/home-bg-jeep.jpg"><meta property="twitter:image" content="//img/home-bg-jeep.jpg"><meta name=title content="16GB NVIDIA Tesla V100 Gets Reprieve; Remains in Production"><meta property="og:title" content="16GB NVIDIA Tesla V100 Gets Reprieve; Remains in Production"><meta property="twitter:title" content="16GB NVIDIA Tesla V100 Gets Reprieve; Remains in Production"><meta name=description content="Back in March at their annual GPU Technology Conference, NVIDIA announced the long-anticipated 32GB version of their flagship Tesla V100 accelerator. By using newer 8-Hi HBM2 memory stacks, NVIDIA was able to double the accelerators previous 16GB of VRAM to a class-leading 32GB. Meanwhile, at the time company representatives told us that the launch of"><meta property="og:description" content="Back in March at their annual GPU Technology Conference, NVIDIA announced the long-anticipated 32GB version of their flagship Tesla V100 accelerator. By using newer 8-Hi HBM2 memory stacks, NVIDIA was able to double the accelerators previous 16GB of VRAM to a class-leading 32GB. Meanwhile, at the time company representatives told us that the launch of"><meta property="twitter:description" content="Back in March at their annual GPU Technology Conference, NVIDIA announced the long-anticipated 32GB version of their flagship Tesla V100 accelerator. By using newer 8-Hi HBM2 memory stacks, NVIDIA was able to double the accelerators previous 16GB of VRAM to a class-leading 32GB. Meanwhile, at the time company representatives told us that the launch of"><meta property="twitter:card" content="summary"><meta name=keyword content><link rel="shortcut icon" href=./img/favicon.ico><title>16GB NVIDIA Tesla V100 Gets Reprieve; Remains in Production |</title><link rel=canonical href=./16gb-nvidia-tesla-v100-gets-reprieve-remains-in-production.html><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cleanwhite/css/bootstrap.min.css><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cleanwhite/css/hugo-theme-cleanwhite.min.css><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cleanwhite/css/zanshang.css><link href=https://cdn.jsdelivr.net/gh/FortAwesome/Font-Awesome@5.15.1/css/all.css rel=stylesheet type=text/css><script src=https://assets.cdnweb.info/hugo/cleanwhite/js/jquery.min.js></script>
<script src=https://assets.cdnweb.info/hugo/cleanwhite/js/bootstrap.min.js></script>
<script src=https://assets.cdnweb.info/hugo/cleanwhite/js/hux-blog.min.js></script></head><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button>
<a class=navbar-brand href=./>VibeBlog</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=./categories/blog>blog</a></li><li><a href=./sitemap.xml>Sitemap</a></li><li><a href=./index.xml>RSS</a></li></ul></div></div></div></nav><script>var $body=document.body,$toggle=document.querySelector(".navbar-toggle"),$navbar=document.querySelector("#huxblog_navbar"),$collapse=document.querySelector(".navbar-collapse");$toggle.addEventListener("click",handleMagic);function handleMagic(){$navbar.className.indexOf("in")>0?($navbar.className=" ",setTimeout(function(){$navbar.className.indexOf("in")<0&&($collapse.style.height="0px")},400)):($collapse.style.height="auto",$navbar.className+=" in")}</script><style type=text/css>header.intro-header{background-image:url(/img/home-bg-jeep.jpg)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags></div><h1>16GB NVIDIA Tesla V100 Gets Reprieve; Remains in Production</h1><h2 class=subheading></h2><span class=meta>Posted by
Martina Birk
on
Wednesday, February 28, 2024</span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><img src=https://cdn.statically.io/img/images.anandtech.com/doci/12809/v100board_678x452.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto><p>Back in March at their annual GPU Technology Conference, <a href=#>NVIDIA announced the long-anticipated 32GB version of their flagship Tesla V100 accelerator</a>. By using newer 8-Hi HBM2 memory stacks, NVIDIA was able to double the accelerator’s previous 16GB of VRAM to a class-leading 32GB. Meanwhile, at the time company representatives told us that the launch of the 32GB model would be a wholesale replacement of the 16GB model, with the smaller version to be phased out and all future cards to go out as the 32GB model.</p><p>However, this week NVIDIA has reached out to inform us that this will not the case, and that the 16GB model is being continued after all.</p><p>In a somewhat odd exchange, the official line from the company is that the previous statement – made in the heat of a pre-briefing Q&A session – was in error, and that the 16GB model was never being discontinued. Instead, NVIDIA’s plan has always been to sell the two models side-by-side. Unfortunately, the company hasn’t been able to make it clear why that information wasn’t presented at the show instead; though what I do know is that this wasn’t caught until customers recently started asking questions.</p><table align=center border=0 cellpadding=0 cellspacing=1 width=650><tbody readability=2><tr class=tgrey readability=2><td align=center colspan=7>NVIDIA Tesla/Titan Family Specification Comparison</td></tr><tr class=tlblue><td width=140>&nbsp;</td><td align=center valign=middle width=126>Tesla V100<br>(SXM2)</td><td align=center valign=middle width=126>Tesla V100<br>(PCIe)</td><td align=center valign=middle width=126>Titan V<br>(PCIe)</td><td align=center valign=middle width=126>Tesla P100<br>(SXM2)</td></tr><tr><td class=tlgrey>CUDA Cores</td><td align=center valign=middle>5120</td><td align=center valign=middle>5120</td><td align=center valign=middle>5120</td><td align=center valign=middle>3584</td></tr><tr><td class=tlgrey>Tensor Cores</td><td align=center valign=middle>640</td><td align=center valign=middle>640</td><td align=center valign=middle>640</td><td align=center valign=middle>N/A</td></tr><tr><td class=tlgrey>Core Clock</td><td align=center valign=middle>?</td><td align=center valign=middle>?</td><td align=center valign=middle>1200MHz</td><td align=center valign=middle>1328MHz</td></tr><tr><td class=tlgrey>Boost Clock</td><td align=center valign=middle>1455MHz</td><td align=center valign=middle>1370MHz</td><td align=center valign=middle>1455MHz</td><td align=center valign=middle>1480MHz</td></tr><tr><td class=tlgrey>Memory Clock</td><td align=center valign=middle>1.75Gbps HBM2</td><td align=center valign=middle>1.75Gbps HBM2</td><td align=center valign=middle>1.7Gbps HBM2</td><td align=center valign=middle>1.4Gbps HBM2</td></tr><tr><td class=tlgrey>Memory Bus Width</td><td align=center valign=middle>4096-bit</td><td align=center valign=middle>4096-bit</td><td align=center valign=middle>3072-bit</td><td align=center valign=middle>4096-bit</td></tr><tr><td class=tlgrey>Memory Bandwidth</td><td align=center valign=middle>900GB/sec</td><td align=center valign=middle>900GB/sec</td><td align=center valign=middle>653GB/sec</td><td align=center valign=middle>720GB/sec</td></tr><tr><td class=tlgrey>VRAM</td><td align=center valign=middle>16GB<br>32GB</td><td align=center valign=middle>16GB<br>32GB</td><td align=center valign=middle>12GB</td><td align=center valign=middle>16GB</td></tr><tr><td class=tlgrey>L2 Cache</td><td align=center valign=middle>6MB</td><td align=center valign=middle>6MB</td><td align=center valign=middle>4.5MB</td><td align=center valign=middle>4MB</td></tr><tr><td class=tlgrey>Half Precision</td><td align=center valign=middle>30 TFLOPS</td><td align=center valign=middle>28 TFLOPS</td><td align=center valign=middle>27.6 TFLOPS</td><td align=center valign=middle>21.2 TFLOPS</td></tr><tr><td class=tlgrey>Single Precision</td><td align=center valign=middle>15 TFLOPS</td><td align=center valign=middle>14 TFLOPS</td><td align=center valign=middle>13.8 TFLOPS</td><td align=center valign=middle>10.6 TFLOPS</td></tr><tr><td class=tlgrey>Double Precision</td><td align=center valign=middle>7.5 TFLOPS</td><td align=center valign=middle>7 TFLOPS</td><td align=center valign=middle>6.9 TFLOPS</td><td align=center valign=middle>5.3 TFLOPS</td></tr><tr readability=2><td class=tlgrey>Tensor Performance<br>(Deep Learning)</td><td align=center valign=middle>120 TFLOPS</td><td align=center valign=middle>112 TFLOPS</td><td align=center valign=middle>110 TFLOPS</td><td align=center valign=middle>N/A</td></tr><tr><td class=tlgrey>GPU</td><td align=center valign=middle>GV100</td><td align=center valign=middle>GV100</td><td align=center valign=middle>GV100</td><td align=center valign=middle>GP100</td></tr><tr><td class=tlgrey>Transistor Count</td><td align=center valign=middle>21B</td><td align=center valign=middle>21B</td><td align=center valign=middle>21.1B</td><td align=center valign=middle>15.3B</td></tr><tr><td class=tlgrey>TDP</td><td align=center valign=middle>300W</td><td align=center valign=middle>250W</td><td align=center valign=middle>250W</td><td align=center valign=middle>300W</td></tr><tr><td class=tlgrey>Form Factor</td><td align=center valign=middle>Mezzanine (SXM2)</td><td align=center valign=middle>PCIe</td><td align=center valign=middle>PCIe</td><td align=center valign=middle>Mezzanine (SXM2)</td></tr><tr><td class=tlgrey>Cooling</td><td align=center valign=middle>Passive</td><td align=center valign=middle>Passive</td><td align=center valign=middle>Active</td><td align=center valign=middle>Passive</td></tr><tr><td class=tlgrey>Manufacturing Process</td><td align=center valign=middle>TSMC 12nm FFN</td><td align=center valign=middle>TSMC 12nm FFN</td><td align=center valign=middle>TSMC 12nm FFN</td><td align=center valign=middle>TSMC 16nm FinFET</td></tr><tr><td class=tlgrey>Architecture</td><td align=center valign=middle>Volta</td><td align=center valign=middle>Volta</td><td align=center valign=middle>Volta</td><td align=center valign=middle>Pascal</td></tr></tbody></table><p>But whatever the internal rationale and timetable on NVIDIA’s part, the end result is that at least for the foreseeable future, NVIDIA is going to be offering multiple V100 capacities across its lineup, including both the SXM2 and PCIe form factors. For NVIDIA's customers then, they now have a choice to make on capacity. The larger version is clocked identically to its 16GB counterpart, so it doesn't have an immediate performance advantage outside of memory capacity. However in cases where a dataset that doesn't fit in the 16GB model fits in the 32GB model, the performance differences can be very significant due to the large impact of memory thrashing; NVIDIA is advertising a 50% performance boost in some memory-limited HPC applications thanks to the larger RAM pool.</p><p>Finally, the company also confirmed that these cards will be priced differently. However they aren’t sharing the list prices for the parts, so it’s not clear whether the new pricing structure gives the 16GB model a price cut, or if the 32GB model is being offered at a price premium.</p><p>Source: NVIDIA</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH5zhI9yZmpul5d6r8LInaCaZaSawK2tjK9oaWhdnLK1v4yrnKmqmZrDpnnRnqSaoZ6oeqq6jKmpqJylmMGqu80%3D</p><hr><ul class=pager><li class=previous><a href=./dawn-berlitz-30615.html data-toggle=tooltip data-placement=top title="Dawn~Berlitz | Bulbagarden">&larr;
Previous Post</a></li><li class=next><a href=./sundar-pichai-net-worth.html data-toggle=tooltip data-placement=top title="Sundar Pichai Net Worth: Career &amp;amp; Lifestyle">Next
Post &rarr;</a></li></ul></div><div class="col-lg-2 col-lg-offset-0
visible-lg-block
sidebar-container
catalog-container"><div class=side-catalog><hr class="hidden-sm hidden-xs"><h5><a class=catalog-toggle href=#>CATALOG</a></h5><ul class=catalog-body></ul></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=./tags/>FEATURED TAGS</a></h5><div class=tags></div></section></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"></ul><p class="copyright text-muted">Copyright &copy; VibeBlog 2024<br><a href=https://themes.gohugo.io/hugo-theme-cleanwhite>CleanWhite Hugo Theme</a> |
<iframe style=margin-left:2px;margin-bottom:-5px frameborder=0 scrolling=0 width=100px height=20px src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true"></iframe></p></div></div></div></footer><script>function loadAsync(i,t){var n=document,s="script",e=n.createElement(s),o=n.getElementsByTagName(s)[0];e.src=i,t&&e.addEventListener("load",function(e){t(null,e)},!1),o.parentNode.insertBefore(e,o)}</script><script>$("#tag_cloud").length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js",function(){var e=document.querySelector("nav");e&&FastClick.attach(e)})</script><script type=text/javascript>function generateCatalog(e){_containerSelector="div.post-container";var t,n,s,o,i,r=$(_containerSelector),a=r.find("h1,h2,h3,h4,h5,h6");return $(e).html(''),a.each(function(){n=$(this).prop("tagName").toLowerCase(),i="#"+$(this).prop("id"),s=$(this).text(),t=$('<a href="'+i+'" rel="nofollow">'+s+"</a>"),o=$('<li class="'+n+'_nav"></li>').append(t),$(e).append(o)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(e){e.preventDefault(),$(".side-catalog").toggleClass("fold")}),loadAsync("https://assets.cdnweb.info/hugo/cleanwhite/js/jquery.nav.js",function(){$(".catalog-body").onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>